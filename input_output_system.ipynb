{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leaky integrator model of Echo State Network\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_dimensions(s, targetlength):\n",
    "    if s is not None:\n",
    "        s = np.array(s)\n",
    "        if s.ndim == 0:\n",
    "            s = np.array([s] * targetlength)\n",
    "        elif s.ndim == 1:\n",
    "            if not len(s) == targetlength:\n",
    "                raise ValueError(\"arg must have length \" + str(targetlength))\n",
    "        else:\n",
    "            raise ValueError(\"Invalid argument\")\n",
    "    return s\n",
    "\n",
    "\n",
    "def identity(x):\n",
    "    return x\n",
    "\n",
    "\n",
    "class LI_ESN_internal:\n",
    "\n",
    "    def __init__(self, n_inputs, n_outputs, n_reservoir=200,\n",
    "                 spectral_radius=0.95, sparsity=0, noise=0.001, input_shift=None,\n",
    "                 input_scaling=None, feedback_scaling=None,\n",
    "                 teacher_scaling=None, teacher_shift=None,\n",
    "                 out_activation=identity, inverse_out_activation=identity,\n",
    "                 input_node=30, output_node=30,\n",
    "                 random_state=None, time_scale=None):\n",
    "        # check for proper dimensionality of all arguments and write them down.\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_reservoir = n_reservoir\n",
    "        self.n_outputs = n_outputs\n",
    "        self.spectral_radius = spectral_radius\n",
    "        self.sparsity = sparsity\n",
    "        self.noise = noise\n",
    "        self.input_node = input_node\n",
    "        self.output_node = output_node\n",
    "        self.input_shift = correct_dimensions(input_shift, n_inputs)\n",
    "        self.input_scaling = correct_dimensions(input_scaling, n_inputs)\n",
    "\n",
    "        self.teacher_scaling = teacher_scaling\n",
    "        self.teacher_shift = teacher_shift\n",
    "\n",
    "        self.out_activation = out_activation\n",
    "        self.inverse_out_activation = inverse_out_activation\n",
    "        self.random_state = random_state\n",
    "        self.time_scale = time_scale\n",
    "\n",
    "        # the given random_state might be either an actual RandomState object,\n",
    "        # a seed or None (in which case we use numpy's builtin RandomState)\n",
    "        if isinstance(random_state, np.random.RandomState):\n",
    "            self.random_state_ = random_state\n",
    "        elif random_state:\n",
    "            try:\n",
    "                self.random_state_ = np.random.RandomState(random_state)\n",
    "            except TypeError as e:\n",
    "                raise Exception(\"Invalid seed: \" + str(e))\n",
    "        else:\n",
    "            self.random_state_ = np.random.mtrand._rand\n",
    "\n",
    "        self.initweights()\n",
    "\n",
    "    def initweights(self):\n",
    "        # initialize recurrent weights:\n",
    "        # begin with a random matrix centered around zero:\n",
    "        W = np.random.normal(0, 1/self.n_reservoir, (self.n_reservoir, self.n_reservoir))\n",
    "        \n",
    "        # delete the fraction of connections given by (self.sparsity):\n",
    "        W[self.random_state_.rand(*W.shape) < self.sparsity] = 0\n",
    "        \n",
    "        # compute the spectral radius of these weights:\n",
    "        radius = np.max(np.abs(np.linalg.eigvals(W)))\n",
    "        \n",
    "        # rescale them to reach the requested spectral radius:\n",
    "        self.W = W * (self.spectral_radius / radius)\n",
    "\n",
    "        # random input weights:\n",
    "        self.W_in = (np.random.rand(self.n_reservoir, self.n_inputs) * 2 - 1)*0.1\n",
    "        self.W_in[self.input_node:] = [0]\n",
    "\n",
    "    def _update(self, state, input_pattern):\n",
    "        # leaky integrator model\n",
    "        preactivation = (np.dot(self.W, state)\n",
    "                         + np.dot(self.W_in, input_pattern))\n",
    "        state = (1 - self.time_scale) * state + self.time_scale * np.tanh(preactivation)\n",
    "        return (state + self.noise * self.time_scale * (self.random_state_.rand(self.n_reservoir) - 0.5))\n",
    "\n",
    "    def calc_lyapunov_exp(self, inputs, initial_distance, n):\n",
    "        if inputs.ndim < 2:\n",
    "            inputs = np.reshape(inputs, (len(inputs), -1))\n",
    "        states1 = np.zeros((inputs.shape[0], self.n_reservoir))\n",
    "        states2 = np.zeros((inputs.shape[0], self.n_reservoir))\n",
    "        transient = min(int(inputs.shape[0] / 10), 100)\n",
    "        for i in range(1, transient):\n",
    "            states1[i, :] = self._update(states1[i-1], inputs[i, :])\n",
    "        states2[transient-1, :] = states1[transient-1, :]\n",
    "        states2[transient-1, n] = states2[transient-1, n] + initial_distance\n",
    "        gamma_k_list = []\n",
    "        for k in range(transient, inputs.shape[0]):\n",
    "            states1[k, :] = self._update(states1[k-1], inputs[k, :])\n",
    "            states2[k, :] = self._update(states2[k-1], inputs[k, :])\n",
    "            gamma_k = np.linalg.norm(states2[k, :]-states1[k, :])\n",
    "            # print(gamma_k/initial_distance)\n",
    "            gamma_k_list.append(gamma_k/initial_distance)\n",
    "            states2[k, :] = states1[k, :] + (initial_distance/gamma_k)*(states2[k, :]-states1[k, :])\n",
    "        lyapunov_exp = np.mean(np.log(gamma_k_list))\n",
    "        return lyapunov_exp\n",
    "            \n",
    "    \n",
    "    def fit(self, inputs, outputs):\n",
    "        if inputs.ndim < 2:\n",
    "            inputs = np.reshape(inputs, (len(inputs), -1))\n",
    "        if outputs.ndim < 2:\n",
    "            outputs = np.reshape(outputs, (len(outputs), -1))\n",
    "        inputs_scaled = inputs\n",
    "        teachers_scaled = outputs\n",
    "\n",
    "        # step the reservoir through the given input,output pairs:\n",
    "        states = np.zeros((inputs.shape[0], self.n_reservoir))\n",
    "        for n in range(1, inputs.shape[0]):\n",
    "            states[n, :] = self._update(states[n - 1], inputs_scaled[n, :])\n",
    "        transient = min(int(inputs.shape[0] / 10), 100)\n",
    "        \n",
    "        self.W_out = np.dot(np.linalg.pinv(states[transient:, -self.output_node:]),teachers_scaled[transient:, :]).T\n",
    "\n",
    "        # remember the last state for later:\n",
    "        self.laststate = states[-1, :]\n",
    "        self.lastinput = inputs[-1, :]\n",
    "        self.lastoutput = teachers_scaled[-1, :]\n",
    "            \n",
    "        # apply learned weights to the collected states:\n",
    "        # print(states.shape)\n",
    "        pred_train = np.dot(states[:, -self.output_node:], self.W_out.T)\n",
    "        # print(self.W_out.T.shape)\n",
    "        return pred_train\n",
    "\n",
    "    def predict(self, inputs, continuation=True):\n",
    "        if inputs.ndim < 2:\n",
    "            inputs = np.reshape(inputs, (len(inputs), -1))\n",
    "        n_samples = inputs.shape[0]\n",
    "\n",
    "        if continuation:\n",
    "            laststate = self.laststate\n",
    "            lastinput = self.lastinput\n",
    "            lastoutput = self.lastoutput\n",
    "        else:\n",
    "            laststate = np.zeros(self.n_reservoir)\n",
    "            lastinput = np.zeros(self.n_inputs)\n",
    "            lastoutput = np.zeros(self.n_outputs)\n",
    "\n",
    "        inputs = np.vstack([lastinput, inputs])\n",
    "        states = np.vstack(\n",
    "            [laststate, np.zeros((n_samples, self.n_reservoir))])\n",
    "        outputs = np.vstack(\n",
    "            [lastoutput, np.zeros((n_samples, self.n_outputs))])\n",
    "\n",
    "        for n in range(n_samples):\n",
    "            states[n + 1, :] = self._update(states[n, :], inputs[n + 1, :])\n",
    "            outputs[n + 1, :] = np.dot(self.W_out,states[n + 1, -self.output_node:])\n",
    "\n",
    "        return self.out_activation(outputs[1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data_for_narma(length):\n",
    "    tau = 0.01\n",
    "    buffer = 100\n",
    "    x = np.random.rand(length+100)*0.5\n",
    "    y = np.zeros(length)\n",
    "    for i in range(length):\n",
    "        if i < 29:\n",
    "            y[i] = 0.2*y[i-1] + 0.004*y[i-1]*np.sum(np.hstack((y[i-29:], y[:i]))) + 1.5*x[i-29+100]*x[i+100] + 0.001\n",
    "        else:\n",
    "            y[i] = 0.2*y[i-1] + 0.004*y[i-1]*np.sum(np.hstack((y[i-29:i]))) + 1.5*x[i-29+100]*x[i+100] + 0.001\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 155\n",
    "# spectral radius\n",
    "rou = 0.99\n",
    "trainlen = 1200\n",
    "future = 1000\n",
    "buffer = 100\n",
    "\n",
    "\n",
    "time_scale = np.ones(N)*0.95\n",
    "# time_scale[60:65] = 0.1\n",
    "# time_scale[:2] = 0.01\n",
    "# time_scale[2] = 0.05\n",
    "# time_scale[-5:-2] = 0.7\n",
    "# time_scale[50] = 0.05\n",
    "# time_scale[55:57] = 0.2\n",
    "# time_scale[57:60] = 0.1\n",
    "# time_scale[-3:] = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, target = make_data_for_narma(trainlen+future)\n",
    "esn = LI_ESN_internal(n_inputs=1,\n",
    "                      n_outputs=1,\n",
    "                      n_reservoir=N,\n",
    "                      noise=1e-9,\n",
    "                      input_node=50,\n",
    "                      output_node=50,\n",
    "                      spectral_radius=rou,\n",
    "                      time_scale=time_scale)\n",
    "\n",
    "\n",
    "pred_training = esn.fit(data[buffer:buffer+trainlen], target[:trainlen])\n",
    "\n",
    "prediction = esn.predict(data[trainlen+buffer:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8184545437502337\n"
     ]
    }
   ],
   "source": [
    "print(np.sqrt(np.mean((np.reshape(prediction, -1)-np.reshape(target[1200:], -1))**2)/np.var(target[1200:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, target = make_data_for_narma(trainlen+future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9103720019568903\n"
     ]
    }
   ],
   "source": [
    "narma_list_normal = []\n",
    "for i in range(200):\n",
    "    esn = LI_ESN_internal(n_inputs=1,\n",
    "                          n_outputs=1,\n",
    "                          n_reservoir=N,\n",
    "                          sparsity=0.98,\n",
    "                          noise=1e-9,\n",
    "                          input_node=50,\n",
    "                          output_node=50,\n",
    "                          spectral_radius=rou,\n",
    "                          time_scale=time_scale)\n",
    "\n",
    "\n",
    "    pred_training = esn.fit(data[buffer:buffer+trainlen], target[:trainlen])\n",
    "\n",
    "    prediction = esn.predict(data[trainlen+buffer:])\n",
    "    narma = np.sqrt(np.mean((np.reshape(prediction, -1)-np.reshape(target[1200:], -1))**2)/np.var(target[1200:]))\n",
    "    narma_list_normal.append(narma)\n",
    "print(np.mean(narma_list_normal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9235153324903448\n"
     ]
    }
   ],
   "source": [
    "narma_list_slow = []\n",
    "time_scale = np.ones(N)*1.0\n",
    "time_scale[60:65] = 0.5\n",
    "time_scale[:2] = 0.01\n",
    "# time_scale[2] = 0.05\n",
    "# time_scale[-5:-2] = 0.7\n",
    "# time_scale[50] = 0.05\n",
    "# time_scale[55:57] = 0.2\n",
    "# time_scale[57:60] = 0.1\n",
    "time_scale[-3:] = 0.1\n",
    "for i in range(200):\n",
    "    esn = LI_ESN_internal(n_inputs=1,\n",
    "                          n_outputs=1,\n",
    "                          n_reservoir=N,\n",
    "                          sparsity=0.98,\n",
    "                          noise=1e-9,\n",
    "                          input_node=50,\n",
    "                          output_node=50,\n",
    "                          spectral_radius=rou,\n",
    "                          time_scale=time_scale)\n",
    "\n",
    "\n",
    "    pred_training = esn.fit(data[buffer:buffer+trainlen], target[:trainlen])\n",
    "\n",
    "    prediction = esn.predict(data[trainlen+buffer:])\n",
    "    narma = np.sqrt(np.mean((np.reshape(prediction, -1)-np.reshape(target[1200:], -1))**2)/np.var(target[1200:]))\n",
    "    narma_list_slow.append(narma)\n",
    "print(np.mean(narma_list_slow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117efe208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(narma_list_normal, 100, range=(0.75, 1.05))\n",
    "plt.hist(narma_list_slow, 100, range=(0.75, 1.05))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7627683318719531"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(narma_list_slow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "print(len(narma_list_slow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8799598208642465\n"
     ]
    }
   ],
   "source": [
    "narma = np.sqrt(np.mean((np.reshape(prediction, -1)-np.reshape(target[1200:], -1))**2)/np.var(target[1200:]))\n",
    "print(narma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.007729949294486688"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "esn.calc_lyapunov_exp(data[buffer:buffer+trainlen], 1e-12, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def memory_capacity(L, buffer, data, output_data):\n",
    "    trainlen = 1200\n",
    "    MC = 0\n",
    "    for k in range(L):\n",
    "        cov_matrix = np.cov(np.array([data[trainlen+buffer-(k+1): trainlen+buffer-(k+1)+1000],output_data.T[k]]))\n",
    "        MC_k = cov_matrix[0][1]**2\n",
    "        # print(MC_k)\n",
    "        MC_k = MC_k / (np.var(data[trainlen+buffer:])*np.var(output_data.T[k]))\n",
    "        # print(np.var(data[trainlen+buffer:])*np.var(output_data.T[k]))\n",
    "        # print(MC_k)\n",
    "        MC += MC_k\n",
    "    return MC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.21613574345129\n"
     ]
    }
   ],
   "source": [
    "N = 155\n",
    "# delayed signal\n",
    "L = int(100*1.4)\n",
    "time_scale = np.ones(N)*0.95\n",
    "\n",
    "buffer = L\n",
    "total_len = 2200 + buffer\n",
    "tau = 0.01\n",
    "data = (np.random.rand(total_len)*2-1)*tau\n",
    "\n",
    "\n",
    "esn = LI_ESN_internal(n_inputs=1,\n",
    "                      n_outputs=L,\n",
    "                      n_reservoir=N,\n",
    "                      noise=0,\n",
    "                      internal_node=5,\n",
    "                      spectral_radius=rou,\n",
    "                      time_scale=time_scale)\n",
    "\n",
    "\n",
    "target = np.zeros((total_len - buffer, L))\n",
    "for i in range(L):\n",
    "    target.T[i][:] = data[buffer-(i+1):-(i+1)]\n",
    "\n",
    "pred_training = esn.fit(data[buffer:trainlen+buffer], target[:trainlen])\n",
    "\n",
    "prediction = esn.predict(data[trainlen+buffer:])\n",
    "\n",
    "\n",
    "    \n",
    "print(memory_capacity(L, buffer, data, prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
