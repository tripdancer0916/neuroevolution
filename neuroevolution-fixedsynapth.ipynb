{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Leaky integrator model of Echo State Network\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PPL_SIZE = 30\n",
    "N_NODES = 155\n",
    "INTERNAL_NODE = 5\n",
    "N_EDGE = 2280\n",
    "N_TEST = 20\n",
    "SPECT_RADIUS = 0.99\n",
    "MUTATION_GROWTH = 8\n",
    "REWIRING_GROWTH = 15\n",
    "MATING_GROWTH = 15\n",
    "W_IN = (np.random.rand(N_NODES, 1) * 2 - 1)*0.1\n",
    "W_IN[-INTERNAL_NODE:] = [0]\n",
    "\n",
    "trainlen = 1200\n",
    "future = 1000\n",
    "buffer = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def correct_dimensions(s, targetlength):\n",
    "    if s is not None:\n",
    "        s = np.array(s)\n",
    "        if s.ndim == 0:\n",
    "            s = np.array([s] * targetlength)\n",
    "        elif s.ndim == 1:\n",
    "            if not len(s) == targetlength:\n",
    "                raise ValueError(\"arg must have length \" + str(targetlength))\n",
    "        else:\n",
    "            raise ValueError(\"Invalid argument\")\n",
    "    return s\n",
    "\n",
    "\n",
    "def identity(x):\n",
    "    return x\n",
    "\n",
    "\n",
    "class LI_ESN_internal:\n",
    "\n",
    "    def __init__(self, n_inputs, n_outputs, n_reservoir=200, W=None, W_in=None,\n",
    "                 noise=0.001, input_shift=None,\n",
    "                 input_scaling=None, feedback_scaling=None,\n",
    "                 teacher_scaling=None, teacher_shift=None,\n",
    "                 out_activation=identity, inverse_out_activation=identity,\n",
    "                 internal_node=5,\n",
    "                 random_state=None, time_scale=None):\n",
    "        # check for proper dimensionality of all arguments and write them down.\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_reservoir = n_reservoir\n",
    "        self.n_outputs = n_outputs\n",
    "        self.noise = noise\n",
    "        self.internal_node = internal_node\n",
    "        self.input_shift = correct_dimensions(input_shift, n_inputs)\n",
    "        self.input_scaling = correct_dimensions(input_scaling, n_inputs)\n",
    "\n",
    "        self.teacher_scaling = teacher_scaling\n",
    "        self.teacher_shift = teacher_shift\n",
    "\n",
    "        self.out_activation = out_activation\n",
    "        self.inverse_out_activation = inverse_out_activation\n",
    "        self.random_state = random_state\n",
    "        self.time_scale = time_scale\n",
    "        self.W = W\n",
    "        self.W_in = W_in\n",
    "\n",
    "        # the given random_state might be either an actual RandomState object,\n",
    "        # a seed or None (in which case we use numpy's builtin RandomState)\n",
    "        if isinstance(random_state, np.random.RandomState):\n",
    "            self.random_state_ = random_state\n",
    "        elif random_state:\n",
    "            try:\n",
    "                self.random_state_ = np.random.RandomState(random_state)\n",
    "            except TypeError as e:\n",
    "                raise Exception(\"Invalid seed: \" + str(e))\n",
    "        else:\n",
    "            self.random_state_ = np.random.mtrand._rand\n",
    "\n",
    "    def _update(self, state, input_pattern):\n",
    "        # leaky integrator model:\n",
    "        # it can adjust timescales for each neurons.\n",
    "        preactivation = (np.dot(self.W, state) + np.dot(self.W_in, input_pattern))\n",
    "        state = (1 - self.time_scale) * state + self.time_scale * np.tanh(preactivation)\n",
    "        return (state + self.noise * self.time_scale * (self.random_state_.rand(self.n_reservoir) - 0.5))\n",
    "\n",
    "    def calc_lyapunov_exp(self, inputs, initial_distance, n):\n",
    "        if inputs.ndim < 2:\n",
    "            inputs = np.reshape(inputs, (len(inputs), -1))\n",
    "        states1 = np.zeros((inputs.shape[0], self.n_reservoir))\n",
    "        states2 = np.zeros((inputs.shape[0], self.n_reservoir))\n",
    "        transient = min(int(inputs.shape[0] / 10), 100)\n",
    "        for i in range(1, transient):\n",
    "            states1[i, :] = self._update(states1[i-1], inputs[i, :])\n",
    "        states2[transient-1, :] = states1[transient-1, :]\n",
    "        states2[transient-1, n] = states2[transient-1, n] + initial_distance\n",
    "        gamma_k_list = []\n",
    "        for k in range(transient, inputs.shape[0]):\n",
    "            states1[k, :] = self._update(states1[k-1], inputs[k, :])\n",
    "            states2[k, :] = self._update(states2[k-1], inputs[k, :])\n",
    "            gamma_k = np.linalg.norm(states2[k, :]-states1[k, :])\n",
    "            gamma_k_list.append(gamma_k/initial_distance)\n",
    "            states2[k, :] = states1[k, :] + (initial_distance/gamma_k)*(states2[k, :]-states1[k, :])\n",
    "        lyapunov_exp = np.mean(np.log(gamma_k_list))\n",
    "        return lyapunov_exp\n",
    "            \n",
    "    \n",
    "    def fit(self, inputs, outputs):\n",
    "        if inputs.ndim < 2:\n",
    "            inputs = np.reshape(inputs, (len(inputs), -1))\n",
    "        if outputs.ndim < 2:\n",
    "            outputs = np.reshape(outputs, (len(outputs), -1))\n",
    "        inputs_scaled = inputs\n",
    "        teachers_scaled = outputs\n",
    "\n",
    "        # step the reservoir through the given input,output pairs:\n",
    "        states = np.zeros((inputs.shape[0], self.n_reservoir))\n",
    "        for n in range(1, inputs.shape[0]):\n",
    "            states[n, :] = self._update(states[n - 1], inputs_scaled[n, :])\n",
    "        transient = min(int(inputs.shape[0] / 10), 100)\n",
    "        \n",
    "        self.W_out = np.dot(np.linalg.pinv(states[transient:, :-self.internal_node]),teachers_scaled[transient:, :]).T\n",
    "\n",
    "        # remember the last state for later:\n",
    "        self.laststate = states[-1, :]\n",
    "        self.lastinput = inputs[-1, :]\n",
    "        self.lastoutput = teachers_scaled[-1, :]\n",
    "            \n",
    "        # apply learned weights to the collected states:\n",
    "        pred_train = np.dot(states[:, :-self.internal_node], self.W_out.T)\n",
    "        return pred_train\n",
    "\n",
    "    def predict(self, inputs, continuation=True):\n",
    "        if inputs.ndim < 2:\n",
    "            inputs = np.reshape(inputs, (len(inputs), -1))\n",
    "        n_samples = inputs.shape[0]\n",
    "\n",
    "        if continuation:\n",
    "            laststate = self.laststate\n",
    "            lastinput = self.lastinput\n",
    "            lastoutput = self.lastoutput\n",
    "        else:\n",
    "            laststate = np.zeros(self.n_reservoir)\n",
    "            lastinput = np.zeros(self.n_inputs)\n",
    "            lastoutput = np.zeros(self.n_outputs)\n",
    "\n",
    "        inputs = np.vstack([lastinput, inputs])\n",
    "        states = np.vstack(\n",
    "            [laststate, np.zeros((n_samples, self.n_reservoir))])\n",
    "        outputs = np.vstack(\n",
    "            [lastoutput, np.zeros((n_samples, self.n_outputs))])\n",
    "\n",
    "        for n in range(n_samples):\n",
    "            states[n + 1, :] = self._update(states[n, :], inputs[n + 1, :])\n",
    "            outputs[n + 1, :] = np.dot(self.W_out,states[n + 1, :-self.internal_node])\n",
    "\n",
    "        return self.out_activation(outputs[1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_data_for_narma(length):\n",
    "    tau = 0.01\n",
    "    buffer = 100\n",
    "    x = np.random.rand(length+100)*0.5\n",
    "    y = np.zeros(length)\n",
    "    for i in range(length):\n",
    "        if i < 29:\n",
    "            y[i] = 0.2*y[i-1] + 0.004*y[i-1]*np.sum(np.hstack((y[i-29:], y[:i]))) + 1.5*x[i-29+100]*x[i+100] + 0.001\n",
    "        else:\n",
    "            y[i] = 0.2*y[i-1] + 0.004*y[i-1]*np.sum(np.hstack((y[i-29:i]))) + 1.5*x[i-29+100]*x[i+100] + 0.001\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_init_ppl(spectral_radius):\n",
    "    population = []\n",
    "    for i in range(PPL_SIZE):\n",
    "        W = np.ones(N_NODES**2)*(10/N_NODES)\n",
    "        tmp = np.random.choice(N_NODES**2, N_EDGE, replace=False)\n",
    "        mask = [False if i in tmp else True for i in range(N_NODES**2)]\n",
    "        mask = np.array(mask)\n",
    "        W[mask] = 0\n",
    "        W = W.reshape(N_NODES, N_NODES)\n",
    "        # radius = np.max(np.abs(np.linalg.eigvals(W)))\n",
    "        # W = W * (spectral_radius / radius)\n",
    "        population.append([W, 0.0])\n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_scale = np.ones(N_NODES)\n",
    "def generation(time_scale, population, n_ppl=PPL_SIZE, n_test=N_TEST):\n",
    "    data_pool = []\n",
    "    for i in range(len(population)):\n",
    "        esn = LI_ESN_internal(n_inputs=1,\n",
    "                              W=population[i][0],\n",
    "                              W_in=W_IN,\n",
    "                              n_outputs=1,\n",
    "                              n_reservoir=N_NODES,\n",
    "                              noise=0,\n",
    "                              internal_node=INTERNAL_NODE,\n",
    "                              time_scale=time_scale)\n",
    "        fitness_list = []\n",
    "        for k in range(n_test):\n",
    "            data, target = make_data_for_narma(trainlen+future)\n",
    "            pred_training = esn.fit(data[buffer:buffer+trainlen], target[:trainlen])\n",
    "            prediction = esn.predict(data[trainlen+buffer:])\n",
    "            fitness = np.sqrt(np.mean((np.reshape(prediction, -1)-np.reshape(target[trainlen:], -1))**2)/np.var(target[trainlen:]))\n",
    "            fitness_list.append(fitness)\n",
    "        # print(np.mean(fitness_list))\n",
    "        population[i][1] = np.mean(fitness_list)\n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mutation(population, n_growth=MUTATION_GROWTH, n_ppl=PPL_SIZE):\n",
    "    for i in np.random.choice(n_ppl, n_growth, replace=False):\n",
    "        tmp_W = population[i][0].reshape(N_NODES**2)\n",
    "        while True:\n",
    "            mutation_index = np.random.choice(N_NODES**2)\n",
    "            if abs(tmp_W[mutation_index]) > 0:\n",
    "                break\n",
    "        dist_range = 0.1*abs(tmp_W[mutation_index])\n",
    "        tmp_W[mutation_index] = tmp_W[mutation_index] + dist_range*(np.random.rand()*2-1)\n",
    "        population.append([tmp_W.reshape((N_NODES, N_NODES)), 0.0])\n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rewiring(population, n_growth=REWIRING_GROWTH, n_ppl=PPL_SIZE):\n",
    "    for i in np.random.choice(n_ppl, n_growth, replace=False):\n",
    "        tmp_W = population[i][0].reshape(N_NODES**2)\n",
    "        while True:\n",
    "            rewiring_index = np.random.choice(N_NODES**2)\n",
    "            if abs(tmp_W[rewiring_index]) > 0:\n",
    "                break\n",
    "        if np.random.rand() > 0.5:\n",
    "            j = rewiring_index % N_NODES\n",
    "            new_rewiring_index = np.random.choice(N_NODES)*N_NODES+j\n",
    "        else:\n",
    "            i = rewiring_index // N_NODES\n",
    "            new_rewiring_index = i*N_NODES + np.random.choice(N_NODES)\n",
    "        tmp_saved = tmp_W[new_rewiring_index]\n",
    "        tmp_W[new_rewiring_index] = tmp_W[rewiring_index]\n",
    "        tmp_W[rewiring_index] = tmp_saved\n",
    "        population.append([tmp_W.reshape((N_NODES, N_NODES)), 0.0])\n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mating(population, n_growth=MATING_GROWTH, n_ppl=PPL_SIZE):\n",
    "    for n in range(n_growth):\n",
    "        i, j = np.random.choice(n_ppl, 2, replace=False)\n",
    "        overlap = []\n",
    "        oneside_tuple = []\n",
    "        parent1 = population[i][0].reshape(N_NODES**2)\n",
    "        parent2 = population[j][0].reshape(N_NODES**2)\n",
    "        for k in range(N_NODES**2):\n",
    "            if parent1[k]*parent2[k] != 0:\n",
    "                overlap.append(k)\n",
    "            elif parent1[k] != 0 or parent2[k] != 0:\n",
    "                oneside_tuple.append((1 if parent1[k] != 0 else 2, k))\n",
    "        new_W = np.zeros(N_NODES**2)\n",
    "        if len(overlap) > 0:\n",
    "            for edge_index in overlap:\n",
    "                new_W[edge_index] = parent1[edge_index] if np.random.rand() > 0.5 else parent2[edge_index]\n",
    "        selected_index = np.random.choice(len(oneside_tuple), N_EDGE-len(overlap), replace=False)\n",
    "        for edge_index in selected_index:\n",
    "            new_W[oneside_tuple[edge_index][1]] = parent1[oneside_tuple[edge_index][1]] if oneside_tuple[edge_index][0]==1 else parent2[oneside_tuple[edge_index][1]]\n",
    "        population.append([new_W.reshape((N_NODES, N_NODES)), 0.0])\n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def natural_selection(population, n_ppl=PPL_SIZE):\n",
    "    fitness_list = [population[i][1] for i in range(len(population))]\n",
    "    argsort = np.argsort(fitness_list)\n",
    "    population = np.array(population)\n",
    "    sorted_population = population[argsort, :]\n",
    "    population = sorted_population[:n_ppl]\n",
    "    print('best_fitness:', sorted_population[0][1], 'average_fitness:', np.mean([population[i][1] for i in range(n_ppl)]))\n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_fitness: 0.4179409278432722 average_fitness: 0.43451697241890186\n",
      "best_fitness: 0.4168933370125855 average_fitness: 0.43107816624688045\n",
      "best_fitness: 0.41661353148424213 average_fitness: 0.42714179875284836\n",
      "best_fitness: 0.41674302361979876 average_fitness: 0.4260541969942374\n",
      "best_fitness: 0.41526932381557885 average_fitness: 0.42372983317943785\n",
      "best_fitness: 0.4126826263410511 average_fitness: 0.42283766800997735\n",
      "best_fitness: 0.40814964355859784 average_fitness: 0.42111803205126497\n",
      "best_fitness: 0.4092222841092057 average_fitness: 0.42048016990023934\n",
      "best_fitness: 0.4102740258164871 average_fitness: 0.42005788018504403\n",
      "best_fitness: 0.41261002671141866 average_fitness: 0.41990270349917663\n",
      "best_fitness: 0.4112519405950029 average_fitness: 0.4191216158136634\n",
      "best_fitness: 0.41379779873381173 average_fitness: 0.41885889589607106\n",
      "best_fitness: 0.41140348042355396 average_fitness: 0.41789796273848895\n",
      "best_fitness: 0.41268564488494314 average_fitness: 0.41769681260002495\n",
      "best_fitness: 0.40784026951018737 average_fitness: 0.41757186676666147\n",
      "best_fitness: 0.4095004550158697 average_fitness: 0.41797103159383303\n",
      "best_fitness: 0.4122360477664063 average_fitness: 0.41719688667056337\n",
      "best_fitness: 0.41255290565640657 average_fitness: 0.4164771938007671\n",
      "best_fitness: 0.40784102670173167 average_fitness: 0.416493180173066\n",
      "best_fitness: 0.4107627541590199 average_fitness: 0.41703194930883\n",
      "best_fitness: 0.4081223176530619 average_fitness: 0.416979814037829\n"
     ]
    }
   ],
   "source": [
    "init_population = make_init_ppl(SPECT_RADIUS)\n",
    "for generation_idx in range(100):\n",
    "    new_population = mating(init_population)\n",
    "    new_population = rewiring(new_population)\n",
    "    # new_population = mutation(new_population)\n",
    "    new_population = generation(time_scale, new_population)\n",
    "    new_population = natural_selection(new_population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# speciationして構造を保護したほうがいいかもしれない！！！\n",
    "# タスクの選定は大事。J_ijの違いがパフォーマンスに強く影響を与える設定が望ましい。\n",
    "# noiseを加えるのは考えてみてもいいかも。\n",
    "# sparsityを変えてみるとか。\n",
    "# W_inも最適化させた方がいい気がする。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
